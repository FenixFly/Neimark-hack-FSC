{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('keras.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pymorphy2\n",
    "\n",
    "ma = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def clean_text(text):\n",
    "    try:\n",
    "     text = text.replace(\"\\\\\", \" \").replace(u\"╚\", \" \").replace(u\"╩\", \" \")\n",
    "     text = text.lower()\n",
    "     text = re.sub('\\-\\s\\r\\n\\s{1,}|\\-\\s\\r\\n|\\r\\n', '', text) #deleting newlines and line-breaks\n",
    "     text = re.sub('[.,:;_%©?*,!@#$%^&()\\d]|[+=]|[[]|[]]|[/]|\"|\\s{2,}|-', ' ', text) #deleting symbols  \n",
    "     text = \" \".join(ma.parse(str(word))[0].normal_form for word in text.split())\n",
    "     text = ' '.join(word for word in text.split() if len(word)>3)\n",
    "     text = text.encode(\"utf-8\")\n",
    "    except:\n",
    "     print(text)\n",
    "\n",
    "    return text\n",
    "\n",
    "df['Description'] = df.apply(lambda x: clean_text(x['Post_clean']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TNVED</th>\n",
       "      <th>OPISANIE</th>\n",
       "      <th>DATA</th>\n",
       "      <th>Post_clean</th>\n",
       "      <th>TNVED2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8471</td>\n",
       "      <td>УСТРОЙСТВА ВЫЧИСЛИТЕЛЬНЫХ МАШИН - ОТЛАДОЧНАЯ П...</td>\n",
       "      <td>04.10.2021</td>\n",
       "      <td>устройства вычислительных машин отладочная пла...</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6212</td>\n",
       "      <td>БЮСТГАЛЬТЕРЫ ЖЕНСКИЕ. РОСТ ДО 185 СМ,ОБХВАТ ГР...</td>\n",
       "      <td>20.09.2021</td>\n",
       "      <td>бюстгальтеры женские рост 185 см обхват груди ...</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8548</td>\n",
       "      <td>ЭЛЕКТРИЧЕСКИЕ ЧАСТИ ОБОРУДОВАНИЯ:</td>\n",
       "      <td>24.09.2021</td>\n",
       "      <td>электрические части оборудования</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4403</td>\n",
       "      <td>ПИЛОВОЧНИК ОСИНОВЫЙ (ТОПОЛЬ ДРОЖАЩИЙ (ОСИНА) \"...</td>\n",
       "      <td>12.10.2021</td>\n",
       "      <td>пиловочник осиновый тополь дрожащий осина popu...</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9507</td>\n",
       "      <td>ПРИНАДЛЕЖНОСТИ ДЛЯ РЫБНОЙ ЛОВЛИ: БЛЕСНА ВРАЩАЮ...</td>\n",
       "      <td>17.09.2021</td>\n",
       "      <td>принадлежности рыбной ловли блесна вращающаяся...</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201727</th>\n",
       "      <td>4016</td>\n",
       "      <td>КОЛЬЦО УПЛОТНИТЕЛЬНОЕ ИЗ НЕПОРИСТОЙ ВУЛКАНИЗИР...</td>\n",
       "      <td>16.09.2021</td>\n",
       "      <td>кольцо уплотнительное непористой вулканизирова...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201728</th>\n",
       "      <td>8512</td>\n",
       "      <td>КОМПОНЕНТЫ, ПОСТАВЛЯЕМЫЕ В КАЧЕСТВЕ СМЕННЫХ (З...</td>\n",
       "      <td>13.10.2021</td>\n",
       "      <td>компоненты поставляемые качестве сменных запас...</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201729</th>\n",
       "      <td>7326</td>\n",
       "      <td>ИЗДЕЛИЯ ИЗ ЧЕРНЫХ МЕТАЛЛОВ КОМБИНИРОВАННОЙ ОБР...</td>\n",
       "      <td>12.10.2021</td>\n",
       "      <td>изделия черных металлов комбинированной обрабо...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201730</th>\n",
       "      <td>8708</td>\n",
       "      <td>ЧАСТИ И ПРИНАДЛЕЖНОСТИ КУЗОВОВ ДЛЯ ПРОМ. СБОРК...</td>\n",
       "      <td>20.10.2021</td>\n",
       "      <td>части принадлежности кузовов пром сборки мотор...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201731</th>\n",
       "      <td>8415</td>\n",
       "      <td>ЗАПАСНЫЕ ЧАСТИ ДЛЯ РЕМОНТА И ОБСЛУЖИВАНИЯ ТРАН...</td>\n",
       "      <td>30.09.2021</td>\n",
       "      <td>запасные части ремонта обслуживания транспортн...</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201732 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TNVED                                           OPISANIE        DATA  \\\n",
       "0        8471  УСТРОЙСТВА ВЫЧИСЛИТЕЛЬНЫХ МАШИН - ОТЛАДОЧНАЯ П...  04.10.2021   \n",
       "1        6212  БЮСТГАЛЬТЕРЫ ЖЕНСКИЕ. РОСТ ДО 185 СМ,ОБХВАТ ГР...  20.09.2021   \n",
       "2        8548                  ЭЛЕКТРИЧЕСКИЕ ЧАСТИ ОБОРУДОВАНИЯ:  24.09.2021   \n",
       "3        4403  ПИЛОВОЧНИК ОСИНОВЫЙ (ТОПОЛЬ ДРОЖАЩИЙ (ОСИНА) \"...  12.10.2021   \n",
       "4        9507  ПРИНАДЛЕЖНОСТИ ДЛЯ РЫБНОЙ ЛОВЛИ: БЛЕСНА ВРАЩАЮ...  17.09.2021   \n",
       "...       ...                                                ...         ...   \n",
       "201727   4016  КОЛЬЦО УПЛОТНИТЕЛЬНОЕ ИЗ НЕПОРИСТОЙ ВУЛКАНИЗИР...  16.09.2021   \n",
       "201728   8512  КОМПОНЕНТЫ, ПОСТАВЛЯЕМЫЕ В КАЧЕСТВЕ СМЕННЫХ (З...  13.10.2021   \n",
       "201729   7326  ИЗДЕЛИЯ ИЗ ЧЕРНЫХ МЕТАЛЛОВ КОМБИНИРОВАННОЙ ОБР...  12.10.2021   \n",
       "201730   8708  ЧАСТИ И ПРИНАДЛЕЖНОСТИ КУЗОВОВ ДЛЯ ПРОМ. СБОРК...  20.10.2021   \n",
       "201731   8415  ЗАПАСНЫЕ ЧАСТИ ДЛЯ РЕМОНТА И ОБСЛУЖИВАНИЯ ТРАН...  30.09.2021   \n",
       "\n",
       "                                               Post_clean  TNVED2  \n",
       "0       устройства вычислительных машин отладочная пла...      84  \n",
       "1       бюстгальтеры женские рост 185 см обхват груди ...      62  \n",
       "2                        электрические части оборудования      85  \n",
       "3       пиловочник осиновый тополь дрожащий осина popu...      44  \n",
       "4       принадлежности рыбной ловли блесна вращающаяся...      95  \n",
       "...                                                   ...     ...  \n",
       "201727  кольцо уплотнительное непористой вулканизирова...      40  \n",
       "201728  компоненты поставляемые качестве сменных запас...      85  \n",
       "201729  изделия черных металлов комбинированной обрабо...      73  \n",
       "201730  части принадлежности кузовов пром сборки мотор...      87  \n",
       "201731  запасные части ремонта обслуживания транспортн...      84  \n",
       "\n",
       "[201732 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего категорий: 64\n"
     ]
    }
   ],
   "source": [
    "categories = {}\n",
    "for key,value in enumerate(df['TNVED2'].unique()):\n",
    "    categories[value] = key + 1\n",
    "\n",
    "# Запишем в новую колонку числовое обозначение категории \n",
    "df['category_code'] = df['TNVED2'].map(categories)\n",
    "\n",
    "total_categories = len(df['TNVED2'].unique()) + 1\n",
    "print('Всего категорий: {}'.format(total_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('dataframe_ver_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('dataframe_ver_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-9c00c369bae6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmax_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdesc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdescriptions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdesc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmax_words\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mmax_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "descriptions = df['Description']\n",
    "categories = df[u'category_code']\n",
    "\n",
    "# Посчитаем максимальную длинну текста описания в словах\n",
    "max_words = 0\n",
    "for desc in descriptions:\n",
    "    words = len(desc.split())\n",
    "    if words > max_words:\n",
    "        max_words = words\n",
    "print('Максимальная длина описания: {} слов'.format(max_words))\n",
    "\n",
    "maxSequenceLength = 55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# создаем единый словарь (слово -> число) для преобразования\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(descriptions.tolist())\n",
    "\n",
    "# Преобразуем все описания в числовые последовательности, заменяя слова на числа по словарю.\n",
    "textSequences = tokenizer.texts_to_sequences(descriptions.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_arrays(strings, labels, train_test_split=0.9):\n",
    "    data_size = len(strings)\n",
    "    test_size = int(data_size - round(data_size * train_test_split))\n",
    "    print(\"Test size: {}\".format(test_size))\n",
    "    \n",
    "    print(\"\\nTraining set:\")\n",
    "    x_train = strings[test_size:]\n",
    "    print(\"\\t - x_train: {}\".format(len(x_train)))\n",
    "    y_train = labels[test_size:]\n",
    "    print(\"\\t - y_train: {}\".format(len(y_train)))\n",
    "    \n",
    "    print(\"\\nTesting set:\")\n",
    "    x_test = strings[:test_size]\n",
    "    print(\"\\t - x_test: {}\".format(len(x_test)))\n",
    "    y_test = labels[:test_size]\n",
    "    print(\"\\t - y_test: {}\".format(len(y_test)))\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_data_from_arrays(textSequences, categories, train_test_split=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = len(tokenizer.word_index)\n",
    "print('В словаре {} слов'.format(total_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 1000\n",
    "\n",
    "print(u'Преобразуем описания заявок в векторы чисел...')\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "X_train = tokenizer.sequences_to_matrix(X_train, mode='binary')\n",
    "X_test = tokenizer.sequences_to_matrix(X_test, mode='binary')\n",
    "print('Размерность X_train:', X_train.shape)\n",
    "print('Размерность X_test:', X_test.shape)\n",
    "\n",
    "print(u'Преобразуем категории в матрицу двоичных чисел '\n",
    "      u'(для использования categorical_crossentropy)')\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# количество эпох\\итераций для обучения\n",
    "epochs = 10\n",
    "\n",
    "print(u'Собираем модель...')\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(num_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(total_categories))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test,\n",
    "                       batch_size=32, verbose=1)\n",
    "print()\n",
    "print(u'Оценка теста: {}'.format(score[0]))\n",
    "print(u'Оценка точности модели: {}'.format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# График точности модели\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# График оценки loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# создаем единый словарь (слово -> число) для преобразования\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(descriptions.tolist())\n",
    "\n",
    "# Преобразуем все описания в числовые последовательности, заменяя слова на числа по словарю.\n",
    "textSequences = tokenizer.texts_to_sequences(descriptions.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X-train, y_train, X_test, y_test = load_data_from_arrays(textSequences, categories, train_test_split=0.8)\n",
    "# Максимальное количество слов в самом длинном описании заявки\n",
    "max_words = 0\n",
    "for desc in descriptions.tolist():\n",
    "    words = len(desc.split())\n",
    "    if words > max_words:\n",
    "        max_words = words\n",
    "print('Максимальное количество слов в самом длинном описании заявки: {} слов'.format(max_words))\n",
    "\n",
    "total_unique_words = len(tokenizer.word_counts)\n",
    "print('Всего уникальных слов в словаре: {}'.format(total_unique_words))\n",
    "\n",
    "maxSequenceLength = max_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = round(total_unique_words/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(descriptions)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxSequenceLength)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxSequenceLength)\n",
    "\n",
    "print('Размерность X_train:', X_train.shape)\n",
    "print('Размерность X_test:', X_test.shape)\n",
    "\n",
    "print(u'Преобразуем категории в матрицу двоичных чисел '\n",
    "      u'(для использования categorical_crossentropy)')\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "y_train = encoder.transform(y_train)\n",
    "y_test = encoder.transform(y_test)\n",
    "\n",
    "num_classes = np.max(y_train) + 1\n",
    "print('Количество категорий для классификации: {}'.format(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "\n",
    "# максимальное количество слов для анализа\n",
    "max_features = vocab_size\n",
    "\n",
    "print(u'Собираем модель...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, maxSequenceLength))\n",
    "model.add(LSTM(32, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print (model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 3\n",
    "\n",
    "print(u'Тренируем модель...')\n",
    "history = model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print()\n",
    "print(u'Оценка теста: {}'.format(score[0]))\n",
    "print(u'Оценка точности модели: {}'.format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imoort matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = epochs\n",
    "plt.plot(np.arange(0, N), history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), history.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), history.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Эффективность обучения\")\n",
    "plt.xlabel(\"Повторения #\")\n",
    "plt.ylabel(\"Ошибки\")\n",
    "plt.legend(loc=\"lower left\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
