{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e25d7265",
   "metadata": {},
   "source": [
    "# Классификация текста с помощью трансформера BERT\n",
    "\n",
    "Оригинальная идея подчерпнута отсюда https://www.kaggle.com/c/learn-ai-bbc и отсюда https://habr.com/ru/post/655517/\n",
    "\n",
    "\n",
    "### Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f0f0b3-93b0-4ed1-ba74-bc1bcf5664da",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb66b01-d303-4c1a-affc-69464d3ec275",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vasiliev\\miniconda3\\envs\\hack\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "class BERT_Arch(nn.Module):\n",
    "    def __init__(self, bert, num_classes = 96):\n",
    "        super(BERT_Arch, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(768,512)\n",
    "        self.fc2 = nn.Linear(512,num_classes)\n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "    \n",
    "    def forward(self, sent_id, mask):\n",
    "        _, cls_hs = self.bert(sent_id, attention_mask = mask, return_dict = False)\n",
    "        x = self.fc1(cls_hs)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "class TansformerRuBERT:\n",
    "    def __init__(self, weights = 'saved_weights_2_digits.pt', dev='cpu'):\n",
    "        # dev='cuda'\n",
    "        self.device = torch.device(dev)\n",
    "        self.bert = AutoModel.from_pretrained(\"DeepPavlov/rubert-base-cased-sentence\")\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased-sentence\")\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.model = BERT_Arch(self.bert)\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model.load_state_dict(torch.load(weights, map_location=torch.device(self.device)))\n",
    "        self.model.eval()\n",
    "        \n",
    "    def predict(self, line):\n",
    "        \n",
    "        sequence = self.tokenizer.encode(line, \n",
    "                                        max_length = 15, \n",
    "                                        padding = 'max_length',\n",
    "                                        truncation = True)\n",
    "        mask = torch.tensor([1]*len(sequence)).to(self.device)\n",
    "        sequence = torch.tensor(sequence).to(self.device)\n",
    "        mask = torch.unsqueeze(mask, 0)\n",
    "        sequence = torch.unsqueeze(sequence, 0)\n",
    "        res = self.model(sequence, mask)\n",
    "        res = int(res.argmax(dim=1).cpu().numpy())\n",
    "        if res> 77:\n",
    "            return res+2\n",
    "        else:\n",
    "            return res+1\n",
    "    \n",
    "myModel = TansformerRuBERT()\n",
    "\n",
    "\n",
    "input_line = 'изделия прочие пластмасс изделия прочих материалов товарных позиций 3901 3914 прочие прочие прочие прочие' \n",
    "res = myModel.predict(input_line)\n",
    "\n",
    "\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
